{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import pymorphy2\n",
    "import re\n",
    "from string import punctuation\n",
    "\n",
    "\n",
    "class WordEncoder:\n",
    "    ru_stopwords = set(stopwords.words(\"russian\"))\n",
    "    morph = pymorphy2.MorphAnalyzer()\n",
    "    \n",
    "    @staticmethod\n",
    "    def fit_transform(sentences: list):\n",
    "        one_hot_words_columns = set()\n",
    "        for sentence in tqdm(sentences):\n",
    "            sentence = WordEncoder.preprocess_sentence(sentence)\n",
    "            for word in sentence:\n",
    "                parse_word = WordEncoder.morph.parse(word)\n",
    "                normal_form = parse_word[0].normal_form\n",
    "                if not ((normal_form in WordEncoder.ru_stopwords) or normal_form.isnumeric() or WordEncoder.is_name(parse_word) or any(x.isdigit() for x in normal_form)):\n",
    "                    one_hot_words_columns.add(normal_form)\n",
    "        one_hot_words_columns = list(one_hot_words_columns)\n",
    "        data = [[None] * len(one_hot_words_columns) for _ in range(len(sentences))]\n",
    "        for i in tqdm(range(len(data))):\n",
    "            sentence = WordEncoder.preprocess_sentence(sentences[i])\n",
    "            for j in range(len(data[i])):\n",
    "                data[i][j] = 1 if one_hot_words_columns[j] in sentence else 0\n",
    "        return pd.DataFrame(data, columns=one_hot_words_columns)\n",
    "    \n",
    "    @staticmethod\n",
    "    def remove_symbols_from_text(text: str, symbols: str) -> str:\n",
    "        return \"\".join([ch for ch in text if ch not in symbols])\n",
    "    \n",
    "    @staticmethod\n",
    "    def preprocess_sentence(sentence: str) -> list[str]:\n",
    "        threshold = 0.5\n",
    "        sentence = sentence.lower()\n",
    "        spec_chars = punctuation + '\\n\\t…—«»'\n",
    "        sentence = WordEncoder.remove_symbols_from_text(sentence, spec_chars)\n",
    "        words = sentence.split()\n",
    "        words = list(filter(lambda word: not re.match(r'[a-z]+', word), words)) # remove english words\n",
    "        return words\n",
    "    \n",
    "    @staticmethod\n",
    "    def is_name(parse_word, threshold_prob = 0.5) -> bool:\n",
    "        for p in parse_word:\n",
    "            if 'Name' in p.tag and p.score >= threshold_prob:\n",
    "                return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "data = pd.read_csv('../static/datasets/modified/bin_classification/train_data.csv', sep=',')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1863/1863 [00:06<00:00, 296.90it/s]\n",
      "100%|██████████| 1863/1863 [00:02<00:00, 888.58it/s]\n",
      "100%|██████████| 800/800 [00:02<00:00, 300.50it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 1247.27it/s]\n"
     ]
    }
   ],
   "source": [
    "encoder = WordEncoder()\n",
    "\n",
    "def get_encoded_df_label(file_path: str):\n",
    "    data = pd.read_csv(file_path, sep=',')\n",
    "    data.dropna(inplace=True)\n",
    "    sentences = data['sentence'].astype(str).tolist()\n",
    "    return encoder.fit_transform(sentences), data['label']\n",
    "\n",
    "\n",
    "X_train, y_train = get_encoded_df_label('../static/datasets/modified/bin_classification/train_data.csv')\n",
    "X_test, y_test = get_encoded_df_label('../static/datasets/modified/bin_classification/validation_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "X_train.to_csv(path_or_buf='../static/datasets/modified/bin_classification/bayes_train.csv', index=False)\n",
    "y_train.to_csv(path_or_buf='../static/datasets/modified/bin_classification/bayes_test.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# X_train = pd.read_csv('../static/datasets/modified/bin_classification/bayes_train.csv')\n",
    "# y_train = pd.read_csv('../static/datasets/modified/bin_classification/bayes_test.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
