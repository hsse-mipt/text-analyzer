{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "import pymorphy2\n",
    "import re\n",
    "import string\n",
    "\n",
    "\n",
    "class WordEncoder:\n",
    "    ru_stopwords = set(stopwords.words(\"russian\"))\n",
    "    morph = pymorphy2.MorphAnalyzer()\n",
    "    \n",
    "    @staticmethod\n",
    "    def fit_transform(sentences: list):\n",
    "        one_hot_words_columns = set()\n",
    "        for sentence in tqdm(sentences):\n",
    "            sentence = WordEncoder.preprocess_sentence(sentence)\n",
    "            for word in sentence:\n",
    "                parse_word = WordEncoder.morph.parse(word)\n",
    "                normal_form = parse_word[0].normal_form\n",
    "                if not (normal_form in WordEncoder.ru_stopwords or normal_form.isnumeric() or WordEncoder.is_name(parse_word) or any(x.isdigit() for x in normal_form)):\n",
    "                    one_hot_words_columns.add(normal_form)\n",
    "        one_hot_words_columns = list(one_hot_words_columns)\n",
    "        data = [[0] * len(one_hot_words_columns)] * len(sentences)\n",
    "        for i in tqdm(range(len(data))):\n",
    "            sentence = WordEncoder.preprocess_sentence(sentences[i])\n",
    "            for j in range(len(data[i])):\n",
    "                data[i][j] = 1 if one_hot_words_columns[j] in sentence else 0\n",
    "        return pd.DataFrame(data, columns=one_hot_words_columns)\n",
    "    \n",
    "    @staticmethod\n",
    "    def remove_symbols_from_text(text: str, symbols: str) -> list[str]:\n",
    "        return \"\".join([ch for ch in text if ch not in symbols])\n",
    "    \n",
    "    @staticmethod\n",
    "    def preprocess_sentence(sentence: str) -> list[str]:\n",
    "        threshold = 0.5\n",
    "        sentence = sentence.lower()\n",
    "        spec_chars = string.punctuation + '\\n\\t…—«»'\n",
    "        sentence = WordEncoder.remove_symbols_from_text(sentence, spec_chars)\n",
    "        words = sentence.split()\n",
    "        words = list(filter(lambda word: not re.match(r'[a-z]+', word), words)) # remove english words\n",
    "        return words\n",
    "    \n",
    "    @staticmethod\n",
    "    def is_name(parse_word, threshold_prob = 0.5) -> bool:\n",
    "        for p in parse_word:\n",
    "            if 'Name' in p.tag and p.score >= threshold_prob:\n",
    "                return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 1863/1863 [00:07<00:00, 260.36it/s]\n",
      "100%|██████████████████████████████████████| 1863/1863 [00:02<00:00, 707.42it/s]\n",
      "100%|██████████████████████████████████████| 2845/2845 [00:09<00:00, 286.96it/s]\n",
      "100%|██████████████████████████████████████| 2845/2845 [00:05<00:00, 566.78it/s]\n"
     ]
    }
   ],
   "source": [
    "encoder = WordEncoder()\n",
    "\n",
    "def get_encoded_df_label(file_path: str):\n",
    "    data = pd.read_csv(file_path, sep='\\t')\n",
    "    sentences = data['sentence'].astype(str).tolist()\n",
    "    return encoder.fit_transform(sentences), data['label']\n",
    "    \n",
    "\n",
    "X_train, y_train = get_encoded_df_label('../static/datasets/modified/bin_classification/train_data.csv')\n",
    "X_test, y_test = get_encoded_df_label('../static/datasets/modified/bin_classification/validation_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('..')\n",
    "import src.metrics.binary_classification as metrics\n",
    "from src.models.baselines import NaiveBayesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "\u001B[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py\u001B[0m in \u001B[0;36mget_loc\u001B[0;34m(self, key, method, tolerance)\u001B[0m\n\u001B[1;32m   3628\u001B[0m             \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 3629\u001B[0;31m                 \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_engine\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_loc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcasted_key\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   3630\u001B[0m             \u001B[0;32mexcept\u001B[0m \u001B[0mKeyError\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0merr\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/_libs/index.pyx\u001B[0m in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/_libs/index.pyx\u001B[0m in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32mpandas/_libs/hashtable_class_helper.pxi\u001B[0m in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32mpandas/_libs/hashtable_class_helper.pxi\u001B[0m in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mKeyError\u001B[0m: 0",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_27197/2621694533.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0mnaive_bayes\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mNaiveBayesClassifier\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m \u001B[0mnaive_bayes\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX_train\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_train\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m~/Desktop/Projects/Text tonality analizator/text_analyzer/notebooks/../src/models/baselines/__init__.py\u001B[0m in \u001B[0;36mfit\u001B[0;34m(self, train_feature_matrix, train_labels)\u001B[0m\n\u001B[1;32m     31\u001B[0m                 train_labels == label]  # выбираем те строки, для которых класс = label\n\u001B[1;32m     32\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mclass_probability\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mlabel\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcurrent_label_feature_matrix\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msize\u001B[0m \u001B[0;34m/\u001B[0m \u001B[0mtrain_feature_matrix\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msize\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 33\u001B[0;31m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdistributions\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mlabel\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     34\u001B[0m             \u001B[0;32mfor\u001B[0m \u001B[0mfeature_ind\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtrain_feature_matrix\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     35\u001B[0m                 \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcurrent_label_feature_matrix\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py\u001B[0m in \u001B[0;36m__getitem__\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   3503\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcolumns\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnlevels\u001B[0m \u001B[0;34m>\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3504\u001B[0m                 \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_getitem_multilevel\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 3505\u001B[0;31m             \u001B[0mindexer\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcolumns\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_loc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   3506\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mis_integer\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mindexer\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3507\u001B[0m                 \u001B[0mindexer\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mindexer\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py\u001B[0m in \u001B[0;36mget_loc\u001B[0;34m(self, key, method, tolerance)\u001B[0m\n\u001B[1;32m   3629\u001B[0m                 \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_engine\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_loc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcasted_key\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3630\u001B[0m             \u001B[0;32mexcept\u001B[0m \u001B[0mKeyError\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0merr\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 3631\u001B[0;31m                 \u001B[0;32mraise\u001B[0m \u001B[0mKeyError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0merr\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   3632\u001B[0m             \u001B[0;32mexcept\u001B[0m \u001B[0mTypeError\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3633\u001B[0m                 \u001B[0;31m# If we have a listlike key, _check_indexing_error will raise\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyError\u001B[0m: 0"
     ]
    }
   ],
   "source": [
    "naive_bayes = NaiveBayesClassifier()\n",
    "naive_bayes.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       0\n",
       "2       0\n",
       "3       0\n",
       "4       0\n",
       "       ..\n",
       "1858    0\n",
       "1859    0\n",
       "1860    0\n",
       "1861    0\n",
       "1862    0\n",
       "Name: подконтрольный, Length: 1863, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col = X_train.shape[1]\n",
    "X_train.iloc[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
