{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "487bdacb",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**<<<<<<< local**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytest\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Таблица сопряжённости** (матрица неточности) содержит сводные показатели качества работы классификатора.\n",
    "* **Строки** соответствуют **фактическим** классам тестового набора;\n",
    "* **Cтолбцы** соответствуют **предсказанным** классом.\n",
    "\n",
    "Таблица содержит четыре сводных показателя, каждый из которых отражает количество объектов в одной и четырех\n",
    "категорий:\n",
    "* **Истинно позитивный** (*True positive*, **TP**) -- объект\n",
    "класса `1` был верно помечен меткой `1`;\n",
    "* **Ложно позитивный** (*False positive*, **FP**) -- объект\n",
    "фактически принадлежит классу `0`, но помечен меткой `1`;\n",
    "* **Истинно отрицательный** (*True negative*, **TN**) -- классификатор\n",
    "верно определил, что объект класса `0` принадлежит классу `0`;\n",
    "* **Ложно отрицательный** (*False negative*, **FN**) -- классификатор\n",
    "пометил объект меткой `0`, однако на самом деле объект принадлежит классу `1`.\n",
    "\n",
    "\n",
    "|                    | Предсказано `0` | Предсказано `1` |\n",
    "|:-------------------|:----------------|:----------------|\n",
    "| **Фактически** `0` | TN              | FP              |\n",
    "| **Фактически** `1` | FN              | TP              |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ConfusionMatrix:\n",
    "    def __init__(self, y_true=None, y_pred=None):\n",
    "        self._confusion_matrix = np.array([[0,0], [0,0]])\n",
    "        if not y_true is None and not y_pred is None:\n",
    "            self.upd(y_true, y_pred)\n",
    "\n",
    "    def upd(self, y_true, y_pred):\n",
    "        for value, prediction in zip(y_true, y_pred):\n",
    "            self._confusion_matrix[value][prediction] += 1\n",
    "\n",
    "    def get(self):\n",
    "        return self._confusion_matrix\n",
    "\n",
    "    def get_flatten(self):\n",
    "        return self._confusion_matrix.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_score(y_true, y_pred):\n",
    "    confusion_matrix = ConfusionMatrix(y_true, y_pred)\n",
    "    tn, fp, fn, tp = confusion_matrix.get_flatten()\n",
    "    return tp / (tp + (fp + fn) / 2)\n",
    "\n",
    "def accuracy_score(y_true, y_pred):\n",
    "    confusion_matrix = ConfusionMatrix(y_true, y_pred)\n",
    "    tn, fp, fn, tp = confusion_matrix.get_flatten()\n",
    "    return (tn + tp) / (tn + fp + fn + tp)\n",
    "\n",
    "def precision_score(y_true, y_pred):\n",
    "    confusion_matrix = ConfusionMatrix(y_true, y_pred)\n",
    "    tn, fp, fn, tp = confusion_matrix.get_flatten()\n",
    "    return tp / (tp + fp)\n",
    "\n",
    "def recall_score(y_true, y_pred):\n",
    "    confusion_matrix = ConfusionMatrix(y_true, y_pred)\n",
    "    tn, fp, fn, tp = confusion_matrix.get_flatten()\n",
    "    return tp / (fn + tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def roc_curve(y_true, y_proba):\n",
    "    tpr, fpr = [], []\n",
    "    thresholds = np.linspace(0, 1, 100)\n",
    "\n",
    "    for threshold in thresholds:\n",
    "        y_pred = np.where(y_proba >= threshold, 1, 0)\n",
    "        confusion_matrix = ConfusionMatrix(y_true, y_pred)\n",
    "        tn, fp, fn, tp = confusion_matrix.get_flatten()\n",
    "        tpr.append(tp / (tp + fn))\n",
    "        fpr.append(fp / (fp + tn))\n",
    "    return fpr, tpr, thresholds\n",
    "\n",
    "def auc(x, y):\n",
    "    s = 0\n",
    "    for i in range(1, len(x)):\n",
    "        s += 0.5 * (x[i] - x[i - 1]) * (y[i] + y[i - 1])\n",
    "    return abs(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sklearn.metrics as metrics\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_computations(y_true, y_pred):\n",
    "    assert math.isclose(f1_score(y_true, y_pred), metrics.f1_score(y_true, y_pred))\n",
    "    assert math.isclose(accuracy_score(y_true, y_pred), metrics.accuracy_score(y_true, y_pred))\n",
    "    assert math.isclose(precision_score(y_true, y_pred), metrics.precision_score(y_true, y_pred))\n",
    "    assert math.isclose(recall_score(y_true, y_pred), metrics.recall_score(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_true = np.array([0,1,1,0,0,1,1,0,0,0])\n",
    "y_pred = np.array([0,1,1,0,0,1,0,1,0,1])\n",
    "y_proba = np.array([(random.randint(0, len(y_true)) / len(y_true)) for i in range(len(y_true))])\n",
    "test_computations(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def test_roc_curve():\n",
    "    x, y, th = roc_curve(y_true, y_proba)\n",
    "    sk_x, sk_y, sk_th = metrics.roc_curve(y_true, y_proba)\n",
    "    assert math.isclose(metrics.auc(x, y), metrics.auc(sk_x, sk_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x, y, th = roc_curve(y_true, y_proba)\n",
    "assert math.isclose(metrics.auc(x, y), auc(x, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6bf4c2",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**=======**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def get_confusion_matrix(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    :param y_true: реальные классы\n",
    "    :param y_pred: предсказанные классы\n",
    "    \"\"\"\n",
    "    confusion_matrix = np.array([[0,0], [0,0]]) # столбец - предсказанный класс; строка - реальный\n",
    "    for value, prediction in zip(y_true, y_pred):\n",
    "        confusion_matrix[value][prediction] += 1\n",
    "    return confusion_matrix\n",
    "\n",
    "\n",
    "def f1_score(y_true, y_pred):\n",
    "    TN, FP, FN, TP = get_confusion_matrix(y_true, y_pred).ravel()\n",
    "    return TP / (TP + (FP + FN) / 2)\n",
    "\n",
    "\n",
    "def accuracy_score(y_true, y_pred):\n",
    "    TN, FP, FN, TP = get_confusion_matrix(y_true, y_pred).ravel()\n",
    "    return (TN + TP) / (TN + FP + FN + TP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import math\n",
    "\n",
    "def test_computations(y_true, y_pred):\n",
    "    assert math.isclose(f1_score(y_true, y_pred), sklearn.metrics.f1_score(y_true, y_pred))\n",
    "    assert math.isclose(accuracy_score(y_true, y_pred), sklearn.metrics.accuracy_score(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "y_true = [0,1,1,0,0,1,1,0,0,0]\n",
    "y_pred = [0,1,1,0,0,1,0,1,0,1]\n",
    "test_computations(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "99019d9f",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**>>>>>>> remote**</span>"
   ]
  }
 ],
 "metadata": {
  "nbdime-conflicts": {
   "local_diff": [
    {
     "key": "kernelspec",
     "op": "add",
     "value": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
     }
    },
    {
     "key": "language_info",
     "op": "add",
     "value": {
      "codemirror_mode": {
       "name": "ipython",
       "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
     }
    }
   ],
   "remote_diff": [
    {
     "key": "kernelspec",
     "op": "add",
     "value": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
     }
    },
    {
     "key": "language_info",
     "op": "add",
     "value": {
      "codemirror_mode": {
       "name": "ipython",
       "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
     }
    }
   ]
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
